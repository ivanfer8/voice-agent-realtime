<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Asistente de Voz Zener - ElevenLabs</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            padding: 40px;
            max-width: 500px;
            width: 100%;
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 10px;
            font-size: 28px;
        }

        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 30px;
            font-size: 14px;
        }

        .status {
            text-align: center;
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            font-weight: 500;
            transition: all 0.3s ease;
        }

        .status.disconnected {
            background: #fee;
            color: #c33;
        }

        .status.connecting {
            background: #fef3cd;
            color: #856404;
        }

        .status.connected {
            background: #d4edda;
            color: #155724;
        }

        .status.talking {
            background: #cce5ff;
            color: #004085;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.02); }
        }

        .button-container {
            display: flex;
            gap: 15px;
            margin-bottom: 30px;
        }

        button {
            flex: 1;
            padding: 15px;
            border: none;
            border-radius: 10px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        #connectBtn {
            background: #667eea;
            color: white;
        }

        #connectBtn:hover:not(:disabled) {
            background: #5568d3;
            transform: translateY(-2px);
        }

        #disconnectBtn {
            background: #f56565;
            color: white;
        }

        #disconnectBtn:hover:not(:disabled) {
            background: #e53e3e;
            transform: translateY(-2px);
        }

        .visualizer {
            width: 100%;
            height: 100px;
            background: #f7fafc;
            border-radius: 10px;
            margin-bottom: 20px;
            position: relative;
            overflow: hidden;
        }

        #canvas {
            width: 100%;
            height: 100%;
        }

        .transcript {
            background: #f7fafc;
            border-radius: 10px;
            padding: 20px;
            max-height: 300px;
            overflow-y: auto;
            margin-bottom: 20px;
        }

        .transcript-item {
            margin-bottom: 15px;
            padding: 10px;
            border-radius: 8px;
        }

        .transcript-item.user {
            background: #e6f3ff;
            border-left: 4px solid #667eea;
        }

        .transcript-item.assistant {
            background: #f0fff4;
            border-left: 4px solid #48bb78;
        }

        .transcript-label {
            font-weight: 600;
            margin-bottom: 5px;
            font-size: 12px;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        .transcript-item.user .transcript-label {
            color: #667eea;
        }

        .transcript-item.assistant .transcript-label {
            color: #48bb78;
        }

        .transcript-text {
            color: #333;
            line-height: 1.5;
        }

        .info {
            text-align: center;
            font-size: 12px;
            color: #666;
            padding: 15px;
            background: #f7fafc;
            border-radius: 10px;
        }

        .info strong {
            color: #333;
        }

        .loading {
            display: inline-block;
            width: 12px;
            height: 12px;
            border: 2px solid #667eea;
            border-radius: 50%;
            border-top-color: transparent;
            animation: spin 0.8s linear infinite;
            margin-left: 5px;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Asistente de Voz Zener</h1>
        <p class="subtitle">Powered by OpenAI + ElevenLabs</p>

        <div id="status" class="status disconnected">
            Desconectado
        </div>

        <div class="button-container">
            <button id="connectBtn">Conectar</button>
            <button id="disconnectBtn" disabled>Desconectar</button>
        </div>

        <div class="visualizer">
            <canvas id="canvas"></canvas>
        </div>

        <div id="transcript" class="transcript">
            <div style="text-align: center; color: #999;">
                La transcripci√≥n aparecer√° aqu√≠...
            </div>
        </div>

        <div class="info">
            <strong>Instrucciones:</strong><br>
            Haz clic en "Conectar" y permite el acceso al micr√≥fono.<br>
            Habla naturalmente y el asistente te responder√° con voz de ElevenLabs.
        </div>
    </div>

    <script>
        // Variables globales
        let ws = null;
        let audioContext = null;
        let microphone = null;
        let processor = null;
        let analyser = null;
        let canvas = null;
        let canvasContext = null;
        let isConnected = false;
        
        // Sistema de cola de audio mejorado
        let audioQueue = [];
        let isPlayingAudio = false;
        let nextPlayTime = 0;
        let audioChunksBuffer = []; // Buffer para acumular chunks peque√±os

        // Elementos del DOM
        const statusDiv = document.getElementById('status');
        const connectBtn = document.getElementById('connectBtn');
        const disconnectBtn = document.getElementById('disconnectBtn');
        const transcriptDiv = document.getElementById('transcript');

        // Inicializar canvas para visualizaci√≥n
        canvas = document.getElementById('canvas');
        canvasContext = canvas.getContext('2d');
        canvas.width = canvas.offsetWidth;
        canvas.height = canvas.offsetHeight;

        /**
         * Actualizar estado de la UI
         */
        function updateStatus(status, message) {
            statusDiv.className = `status ${status}`;
            statusDiv.innerHTML = message;
        }

        /**
         * A√±adir mensaje a la transcripci√≥n
         */
        function addTranscript(role, text) {
            const item = document.createElement('div');
            item.className = `transcript-item ${role}`;
            
            const label = document.createElement('div');
            label.className = 'transcript-label';
            label.textContent = role === 'user' ? 'T√∫' : 'Asistente';
            
            const textDiv = document.createElement('div');
            textDiv.className = 'transcript-text';
            textDiv.textContent = text;
            
            item.appendChild(label);
            item.appendChild(textDiv);
            
            // Limpiar mensaje inicial si existe
            if (transcriptDiv.children[0]?.style?.textAlign === 'center') {
                transcriptDiv.innerHTML = '';
            }
            
            transcriptDiv.appendChild(item);
            transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
        }

        /**
         * Conectar al servidor WebSocket
         */
        async function connect() {
            try {
                updateStatus('connecting', 'Conectando<span class="loading"></span>');
                connectBtn.disabled = true;

                // Solicitar acceso al micr√≥fono
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true,
                        sampleRate: 24000
                    } 
                });

                // Crear AudioContext
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 24000
                });

                // Crear fuente de audio desde el micr√≥fono
                microphone = audioContext.createMediaStreamSource(stream);

                // Crear analizador para visualizaci√≥n
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;
                microphone.connect(analyser);

                // Crear procesador de audio
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                microphone.connect(processor);
                processor.connect(audioContext.destination);

                // Conectar a WebSocket
                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                const wsUrl = `${protocol}//${window.location.host}/ws`;
                
                ws = new WebSocket(wsUrl);

                ws.onopen = () => {
                    console.log('‚úÖ WebSocket conectado');
                    isConnected = true;
                    updateStatus('connected', '‚úì Conectado - Habla cuando quieras');
                    disconnectBtn.disabled = false;

                    // Resetear variables de audio
                    audioQueue = [];
                    audioChunksBuffer = [];
                    isPlayingAudio = false;
                    nextPlayTime = 0;

                    // Inicializar sesi√≥n
                    ws.send(JSON.stringify({ type: 'init' }));

                    // Iniciar visualizaci√≥n
                    drawWaveform();
                };

                ws.onmessage = async (event) => {
                    try {
                        const message = JSON.parse(event.data);
                        
                        // Solo log de mensajes importantes
                        if (!['input_audio_buffer.speech_started', 'input_audio_buffer.speech_stopped'].includes(message.type)) {
                            console.log('üì© Mensaje:', message.type);
                        }

                        // Manejar diferentes tipos de mensajes
                        switch (message.type) {
                            case 'session.ready':
                                console.log('üé§ Sesi√≥n lista');
                                break;

                            case 'input_audio_buffer.speech_started':
                                updateStatus('talking', 'üé§ Escuchando...');
                                break;

                            case 'input_audio_buffer.speech_stopped':
                                updateStatus('connected', '‚è≥ Procesando...');
                                break;

                            case 'conversation.item.input_audio_transcription.completed':
                                const userText = message.transcript;
                                console.log('üë§ Usuario dijo:', userText);
                                addTranscript('user', userText);
                                // Limpiar buffer de audio al iniciar nueva respuesta
                                audioChunksBuffer = [];
                                break;

                            case 'response.audio_transcript.delta':
                                console.log('üí¨ Respuesta parcial:', message.delta);
                                break;

                            case 'response.audio_transcript.done':
                                const assistantText = message.transcript;
                                console.log('ü§ñ Asistente dijo:', assistantText);
                                addTranscript('assistant', assistantText);
                                break;

                            case 'audio.delta':
                                // Audio de ElevenLabs - a√±adir a cola
                                console.log('üîä Audio chunk recibido');
                                updateStatus('talking', 'üîä Reproduciendo respuesta...');
                                queueAudioChunk(message.audio);
                                break;

                            case 'audio.done':
                                console.log('‚úÖ Audio completo - procesando buffer final');
                                // Procesar cualquier chunk restante en el buffer
                                if (audioChunksBuffer.length > 0) {
                                    await processBufferedChunks();
                                }
                                // Esperar a que termine la reproducci√≥n
                                setTimeout(() => {
                                    if (!isPlayingAudio) {
                                        updateStatus('connected', '‚úì Conectado - Habla cuando quieras');
                                    }
                                }, 500);
                                break;

                            case 'error':
                                console.error('‚ùå Error:', message.message);
                                updateStatus('connected', '‚ö†Ô∏è Error: ' + message.message);
                                break;
                        }

                    } catch (error) {
                        console.error('Error procesando mensaje:', error);
                    }
                };

                ws.onerror = (error) => {
                    console.error('‚ùå Error WebSocket:', error);
                    updateStatus('disconnected', '‚ùå Error de conexi√≥n');
                };

                ws.onclose = () => {
                    console.log('üîå WebSocket cerrado');
                    disconnect();
                };

                // Procesar audio del micr√≥fono
                processor.onaudioprocess = (e) => {
                    if (!isConnected || !ws || ws.readyState !== WebSocket.OPEN) {
                        return;
                    }

                    const inputData = e.inputBuffer.getChannelData(0);
                    
                    // Convertir Float32Array a Int16Array (PCM16)
                    const pcm16 = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        const s = Math.max(-1, Math.min(1, inputData[i]));
                        pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }

                    // Convertir a base64
                    const base64 = btoa(String.fromCharCode.apply(null, new Uint8Array(pcm16.buffer)));

                    // Enviar al servidor
                    ws.send(JSON.stringify({
                        type: 'input_audio_buffer.append',
                        audio: base64
                    }));
                };

            } catch (error) {
                console.error('‚ùå Error al conectar:', error);
                updateStatus('disconnected', '‚ùå Error: ' + error.message);
                connectBtn.disabled = false;
            }
        }

        /**
         * A√±adir chunk de audio a la cola con buffer
         */
        function queueAudioChunk(base64Audio) {
            audioChunksBuffer.push(base64Audio);
            
            // Procesar buffer cuando tengamos suficientes chunks o despu√©s de un tiempo
            if (audioChunksBuffer.length >= 3) {
                processBufferedChunks();
            }
        }

        /**
         * Procesar chunks acumulados en el buffer
         */
        async function processBufferedChunks() {
            if (audioChunksBuffer.length === 0) return;
            
            try {
                // Concatenar todos los chunks del buffer
                let totalBytes = 0;
                const decodedChunks = [];
                
                for (const base64Audio of audioChunksBuffer) {
                    const binaryString = atob(base64Audio);
                    const bytes = new Uint8Array(binaryString.length);
                    for (let i = 0; i < binaryString.length; i++) {
                        bytes[i] = binaryString.charCodeAt(i);
                    }
                    decodedChunks.push(bytes);
                    totalBytes += bytes.length;
                }
                
                // Combinar todos los chunks en un solo array
                const combinedBytes = new Uint8Array(totalBytes);
                let offset = 0;
                for (const chunk of decodedChunks) {
                    combinedBytes.set(chunk, offset);
                    offset += chunk.length;
                }
                
                // Convertir a AudioBuffer
                const numSamples = combinedBytes.length / 2;
                const audioBuffer = audioContext.createBuffer(
                    1, // mono
                    numSamples,
                    16000 // sample rate de ElevenLabs
                );

                const channelData = audioBuffer.getChannelData(0);
                const dataView = new DataView(combinedBytes.buffer);
                
                for (let i = 0; i < numSamples; i++) {
                    channelData[i] = dataView.getInt16(i * 2, true) / 32768.0;
                }

                // A√±adir a la cola de reproducci√≥n
                audioQueue.push(audioBuffer);
                
                // Limpiar buffer
                audioChunksBuffer = [];
                
                // Iniciar reproducci√≥n si no est√° en curso
                if (!isPlayingAudio) {
                    playNextInQueue();
                }
                
            } catch (error) {
                console.error('Error procesando buffer de audio:', error);
            }
        }

        /**
         * Reproducir siguiente elemento en la cola
         */
        async function playNextInQueue() {
            if (audioQueue.length === 0) {
                isPlayingAudio = false;
                console.log('üì≠ Cola de audio vac√≠a');
                return;
            }

            isPlayingAudio = true;
            const audioBuffer = audioQueue.shift();

            try {
                // Calcular tiempo de inicio (para reproducci√≥n continua)
                const currentTime = audioContext.currentTime;
                const startTime = Math.max(currentTime, nextPlayTime);
                
                // Crear fuente de audio
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                
                // Programar reproducci√≥n
                source.start(startTime);
                
                // Actualizar tiempo para siguiente chunk
                nextPlayTime = startTime + audioBuffer.duration;
                
                console.log(`üîä Reproduciendo: ${audioBuffer.duration.toFixed(2)}s (cola: ${audioQueue.length})`);

                // Cuando termine, reproducir siguiente
                source.onended = () => {
                    playNextInQueue();
                };

            } catch (error) {
                console.error('Error reproduciendo audio:', error);
                isPlayingAudio = false;
                playNextInQueue(); // Intentar con el siguiente
            }
        }

        /**
         * Desconectar
         */
        function disconnect() {
            isConnected = false;

            // Limpiar colas de audio
            audioQueue = [];
            audioChunksBuffer = [];
            isPlayingAudio = false;
            nextPlayTime = 0;

            if (ws) {
                ws.close();
                ws = null;
            }

            if (processor) {
                processor.disconnect();
                processor = null;
            }

            if (microphone) {
                microphone.disconnect();
                microphone = null;
            }

            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }

            updateStatus('disconnected', 'Desconectado');
            connectBtn.disabled = false;
            disconnectBtn.disabled = true;
        }

        /**
         * Visualizaci√≥n de forma de onda
         */
        function drawWaveform() {
            if (!analyser || !isConnected) return;

            requestAnimationFrame(drawWaveform);

            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            analyser.getByteTimeDomainData(dataArray);

            canvasContext.fillStyle = 'rgb(247, 250, 252)';
            canvasContext.fillRect(0, 0, canvas.width, canvas.height);

            canvasContext.lineWidth = 2;
            canvasContext.strokeStyle = 'rgb(102, 126, 234)';
            canvasContext.beginPath();

            const sliceWidth = canvas.width / bufferLength;
            let x = 0;

            for (let i = 0; i < bufferLength; i++) {
                const v = dataArray[i] / 128.0;
                const y = v * canvas.height / 2;

                if (i === 0) {
                    canvasContext.moveTo(x, y);
                } else {
                    canvasContext.lineTo(x, y);
                }

                x += sliceWidth;
            }

            canvasContext.lineTo(canvas.width, canvas.height / 2);
            canvasContext.stroke();
        }

        // Event listeners
        connectBtn.addEventListener('click', connect);
        disconnectBtn.addEventListener('click', disconnect);

        // Ajustar canvas en resize
        window.addEventListener('resize', () => {
            canvas.width = canvas.offsetWidth;
            canvas.height = canvas.offsetHeight;
        });
    </script>
</body>
</html>